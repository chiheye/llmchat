
# LLMChat

## 项目概述

LLMChat 是一款基于 TypeScript 开发的全栈应用，旨在提供一个集成知识库管理与大型语言模型 (LLM) 交互的智能对话平台。该平台支持用户存储、管理和查询知识内容，并利用 pgvector 进行高效的向量搜索，同时前端基于 Next UI 构建直观美观的用户界面。

同时，LLMChat 允许用户自定义 LLM 的 API URL 和 API Key，以便集成符合 OpenAPI 规范的自定义模型，并提供完善的模型管理功能。平台同时支持团队协作与权限控制，便于多用户共享与协同管理知识库和对话记录。

## 技术栈

- **前端**: TypeScript, Next.js, Next UI
- **后端**: Node.js, Express
- **数据库**: PostgreSQL + pgvector
- **API 规范**: OpenAPI
- **身份认证**: JWT (JSON Web Token)
- **开发工具与管理**: Prisma（数据库迁移及 ORM），ESLint/Prettier（代码规范）

## 安装与配置

### 前提条件

- Node.js 14.x 或更高版本
- PostgreSQL 13.x 或更高版本（需安装 pgvector 扩展）
- npm 或 yarn 包管理器

### 安装步骤

1. **克隆仓库**

```bash
git clone https://github.com/yourusername/llmchat.git
cd llmchat
```

2. **安装依赖**

```bash
npm i --legacy-peer-deps
```

3. **配置环境变量**

创建 `.env` 文件，参考以下示例：

```
DATABASE_URL="postgresql://username:password@localhost:5432/llmchat?schema=public"
JWT_SECRET="your_jwt_secret_key"
OPENAI_API_URL="https://api.openai.com/v1"
OPENAI_API_KEY="your_openai_api_key"
```

4. **初始化数据库**

```bash
npx prisma migrate dev --name init
```

5. **启动应用**

```bash
# 启动前端开发服务器
npm run dev

# 启动后端服务器
npm run server
```

应用将在 http://localhost:3000 (前端) 和 http://localhost:3001 (后端) 运行。

## 使用指南

### 用户注册与登录

1. 访问首页，点击「注册」按钮创建新账户
2. 使用注册的邮箱和密码登录系统

### 知识库管理

1. 在仪表盘页面，点击「创建知识库」按钮
2. 填写知识库名称和描述，点击「创建」按钮
3. 在知识库详情页面，可以添加、编辑和删除文档
4. 支持上传 Markdown、PDF、HTML 等格式的文档

### 模型管理

1. 在仪表盘页面，点击「添加模型」按钮
2. 填写模型名称、描述、API URL 和 API Key
3. 可选择是否设为默认模型
4. 点击「添加」按钮完成创建

### 聊天功能

1. 在仪表盘页面，点击「新建对话」按钮
2. 选择要使用的模型和知识库（可选）
3. 在聊天界面输入问题，系统会结合选定的知识库内容生成回答
4. 支持查看和管理历史对话记录
5. 思维链（CoT）可视化功能，您可以实时观察复杂问题是如何一步步被解析的。这项突破性的功能为 AI 的决策过程提供了前所未有的透明度，让您能够清晰地了解结论是如何得出的。通过将复杂的推理过程分解为清晰的逻辑步骤，您可以更好地理解和验证 AI 的解题思路。无论您是在调试问题、学习知识，还是单纯对 AI 推理感兴趣，思维链可视化都能将抽象思维转化为一种引人入胜的互动体验。
6. 支持更自然、更灵活的 AI 对话方式。通过分支对话功能，您的讨论可以像人类对话一样自然延伸。在任意消息处创建新的对话分支，让您在保留原有上下文的同时，自由探索不同的对话方向。两种强大模式任您选择：延续模式：无缝延展当前讨论，保持宝贵的对话上下文;独立模式：基于任意历史消息，开启全新话题探讨
7. 前所未有的灵活度进行创作与可视化：生成并展示动态 SVG 图形;实时构建与渲染交互式 HTML 页面;输出多种格式的专业文档



## 核心功能

### 用户管理
- **注册、登录与身份认证**  
  - 使用 JWT 实现身份认证和授权  
  - 密码加密存储（采用 bcrypt 加密算法）

### 知识库管理
- **基本操作**: 创建、编辑、删除和查询知识库
- **文档管理**: 支持 Markdown、PDF、HTML 等格式的文档存储与检索  
  - 文档自动分块并进行向量转换（DocumentChunk 表）  
  - 支持富文本编辑与预览
- **高级功能**:
  - **WebSocket 流式响应**：实时返回长文本生成结果，优化用户体验
  - **权限管理**：支持团队协作，设定访问控制与共享机制
  - **模型微调**：允许用户上传数据进行私有 LLM 的微调训练

### AI 交互
- **默认及自定义模型**:  
  - 与默认 LLM 进行对话  
  - 支持用户添加自定义 LLM 模型，实现多模型之间的灵活切换
- **向量搜索增强**:  
  - 采用 pgvector 实现向量化搜索，提升语义检索的准确性

### 模型管理
- 提供完整的模型生命周期管理：添加、编辑、删除和设置默认模型  
- 模型信息存储（包括 API URL、加密存储的 API Key 等）  
- 支持基于 OpenAPI 标准的 API 集成

### 聊天记录管理
- **对话存储与检索**: 保存用户与 AI 的交互历史  
  - 支持聊天记录的查看、搜索和删除  
  - 可选关联知识库和自定义模型信息，便于追踪上下文

### 团队与权限管理
- **团队管理**: 创建团队、邀请成员并管理团队组织结构  
- **成员角色与权限**: 分为管理员、编辑者和查看者，每个角色对应不同操作权限  
- **资源访问控制**: 针对知识库、模型、聊天记录等资源设置细粒度权限

## 项目架构

LLMChat 采用 PostgreSQL 作为核心关系型数据库，并结合 pgvector 实现向量存储与检索。设计上采用分层架构，将前后端职责明确划分，同时支持模块化开发与团队协作。

在数据库设计上，针对文档和知识库的存储采用"主表+分块表